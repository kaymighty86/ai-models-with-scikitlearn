{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ec07194",
   "metadata": {},
   "source": [
    "# Heart Disease Detection AI Model\n",
    "This is a notebook describes the process and steps taken to train an algorithm to be able to detect whether a patient has heart disease or not.  \n",
    "The algorithm that will be used is the __Random Forest Classifier algorithm__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f477004",
   "metadata": {},
   "source": [
    "> Steps being followed;\n",
    "> 1. Get the data\n",
    "> 2. Clean and transform the data (including encoding and scaling)\n",
    "> 3. Fit the model\n",
    "> 4. Test the model\n",
    "> 5. Evaluate the model\n",
    "> 6. Export the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e65e30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary packages that will be used\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cf508b",
   "metadata": {},
   "source": [
    "I'm making use of the heart disease dataset from https://github.com/mrdbourke/zero-to-mastery-ml/blob/master/data/heart-disease.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1486535b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "5   57    1   0       140   192    0        1      148      0      0.4      1   \n",
       "6   56    0   1       140   294    0        0      153      0      1.3      1   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  \n",
       "5   0     1       1  \n",
       "6   0     2       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_disease_raw_ds = pd.read_csv(\"./data/heart-disease.csv\")\n",
    "heart_disease_raw_ds.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e06905",
   "metadata": {},
   "source": [
    "### Data Cleaning/Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba1ca37",
   "metadata": {},
   "source": [
    "**i. Handle missing vaues**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b4df9c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         0\n",
       "sex         0\n",
       "cp          0\n",
       "trestbps    0\n",
       "chol        0\n",
       "fbs         0\n",
       "restecg     0\n",
       "thalach     0\n",
       "exang       0\n",
       "oldpeak     0\n",
       "slope       0\n",
       "ca          0\n",
       "thal        0\n",
       "target      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for issin values\n",
    "heart_disease_raw_ds.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0931bb55",
   "metadata": {},
   "source": [
    "From the check above there are no missing values in the dataset.  \n",
    "The dataset has only numerical features, hence, there is no case of categorical features to encode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60358af",
   "metadata": {},
   "source": [
    "**ii Seperate the test data from the training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1f253b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first, seperate the features (X) and the target (Y)\n",
    "x = heart_disease_raw_ds.drop(\"target\", axis=1)\n",
    "y = heart_disease_raw_ds[\"target\"] #becuase its the target variable is the result it should be put on the y variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a2aa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=20) #the random state is defined to enable us do a reproducable outcome everytime (similar to defining the seed of a numpy random function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e690e6f8",
   "metadata": {},
   "source": [
    "**ii. Feature scaling using normalisation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f6919a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the scaler and column transformer from scikitlearn\n",
    "from sklearn.preprocessing import MinMaxScaler #this performs normalisation\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df0400b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler()\n",
    "features = x.keys() #we are applying scaling to all the determinnant features\n",
    "\n",
    "features_transformer = ColumnTransformer([(\"features_scaling\", min_max_scaler, features)], remainder=\"passthrough\") #transform the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b7ba1cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.76744186, 1.        , 0.        , 0.29245283, 0.29223744,\n",
       "        1.        , 0.5       , 0.74193548, 0.        , 0.03225806,\n",
       "        0.5       , 0.5       , 1.        ],\n",
       "       [0.6744186 , 1.        , 1.        , 0.48113208, 0.24429224,\n",
       "        1.        , 0.        , 0.63709677, 0.        , 0.37096774,\n",
       "        0.        , 0.        , 0.33333333],\n",
       "       [0.74418605, 1.        , 0.        , 0.16981132, 0.19634703,\n",
       "        0.        , 0.        , 0.49193548, 1.        , 0.01612903,\n",
       "        1.        , 0.25      , 0.66666667],\n",
       "       [0.13953488, 1.        , 1.        , 0.43396226, 0.16666667,\n",
       "        0.        , 0.5       , 0.86290323, 1.        , 0.22580645,\n",
       "        1.        , 0.        , 1.        ],\n",
       "       [0.55813953, 0.        , 0.        , 0.71698113, 0.2260274 ,\n",
       "        1.        , 0.        , 0.60483871, 1.        , 0.4516129 ,\n",
       "        0.5       , 0.5       , 0.33333333]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now transform the x_train features\n",
    "x_train_transformed = features_transformer.fit_transform(x_train)\n",
    "\n",
    "x_train_transformed[:5]#preview the transformed x_train features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5fd86f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8       , 1.        , 1.        , 0.475     , 0.51086957,\n",
       "        1.        , 0.        , 0.75438596, 0.        , 0.35      ,\n",
       "        0.5       , 0.25      , 0.5       ],\n",
       "       [0.6       , 1.        , 1.        , 0.25      , 0.1884058 ,\n",
       "        0.        , 0.        , 0.64912281, 0.        , 0.475     ,\n",
       "        0.5       , 0.        , 1.        ],\n",
       "       [0.44444444, 1.        , 0.66666667, 0.25      , 0.17028986,\n",
       "        0.        , 1.        , 0.44736842, 0.        , 0.5       ,\n",
       "        0.5       , 0.75      , 1.        ],\n",
       "       [0.66666667, 1.        , 0.33333333, 0.5       , 0.28985507,\n",
       "        0.        , 1.        , 0.66666667, 1.        , 0.        ,\n",
       "        1.        , 0.        , 0.5       ],\n",
       "       [0.8       , 0.        , 0.66666667, 0.5       , 1.        ,\n",
       "        1.        , 0.        , 0.60526316, 0.        , 0.2       ,\n",
       "        1.        , 0.25      , 0.5       ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transform the x_test data too\n",
    "x_test_transformed = features_transformer.fit_transform(x_test)\n",
    "x_test_transformed[:5] #preview the transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81158da",
   "metadata": {},
   "source": [
    "### Model Fitting\n",
    "> Including hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4207444a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_model = RandomForestClassifier(n_estimators=100, random_state=20) #lets tune the \"random_state\" hyper parameter to 20 since the samples were created with the same random state. For the \"n_estimators\" hyper parameter, it is by default 100 (n_estimators influce the accuracy of models (in some cases, the smaller the number, the more accurate it is (depending on the context)))\n",
    "prediction_model.fit(x_train_transformed, y_train) #fit the model with the transformed features\n",
    "model_prediction = prediction_model.predict(x_test_transformed) #test the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cacd003a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the prediction\n",
    "model_prediction[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0136583a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "      <th>model_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>138</td>\n",
       "      <td>282</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>120</td>\n",
       "      <td>193</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>417</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   65    1   3       138   282    1        0      174      0      1.4      1   \n",
       "1   56    1   3       120   193    0        0      162      0      1.9      1   \n",
       "2   49    1   2       120   188    0        1      139      0      2.0      1   \n",
       "3   59    1   1       140   221    0        1      164      1      0.0      2   \n",
       "4   65    0   2       140   417    1        0      157      0      0.8      2   \n",
       "\n",
       "   ca  thal  target  model_prediction  \n",
       "0   1     2       0                 1  \n",
       "1   0     3       1                 0  \n",
       "2   3     3       0                 0  \n",
       "3   0     2       1                 1  \n",
       "4   1     2       1                 1  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets check the accuracy at a glance from the source table by merging its result to that of the y_test data\n",
    "model_pred = pd.DataFrame({\n",
    "    \"model_prediction\": model_prediction\n",
    "})\n",
    "\n",
    "#merged all the DataFrames together and made sure the indices are reset (becuase we sampled randomly when splitting the train-test data) so that when they're compiled, there won't be any mismatch of rows or NaNs because of randomised indices\n",
    "result_table = pd.concat([x_test.reset_index(drop=True),y_test.reset_index(drop=True),model_pred], axis=1)\n",
    "result_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059bc186",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9f5f1c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6885245901639344"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#quick evaluation\n",
    "prediction_model.score(x_test_transformed, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263265c2",
   "metadata": {},
   "source": [
    "**Evaluation using SciKit Learn metrics functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3d2fcf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "37b61f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.78      0.65        23\n",
      "           1       0.83      0.63      0.72        38\n",
      "\n",
      "    accuracy                           0.69        61\n",
      "   macro avg       0.70      0.71      0.69        61\n",
      "weighted avg       0.73      0.69      0.69        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, model_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "73ea296f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18  5]\n",
      " [14 24]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, model_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "56d716a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6885245901639344\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, model_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ee031a",
   "metadata": {},
   "source": [
    "From the evaluation above, there is a lot of deviatons from the true target value as the algorithm is only 68% accurate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07eb1531",
   "metadata": {},
   "source": [
    "### Export the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "43669c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5f00e589",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(prediction_model, open(\"./exported model/heart_disease_identifier_model.pkl\", \"wb\")) #save the model by writing to the a pickle file. The \"wb\" parameter of the opn() function means \"write binary\". When you're loading a mdoel you use \"rb\" meaning \"read binary\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53091341",
   "metadata": {},
   "source": [
    "I will either further tune the AI model or try another classifier model on this problem till the best result is attained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0a3ad5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
